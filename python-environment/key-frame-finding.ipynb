{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6148bc1e-1f17-4605-bacd-c5a4a1f06c3e",
   "metadata": {},
   "source": [
    "# Key frame finding \n",
    "The algorithm has been adapted from [pedrofrodenas/blur-Detection-Haar-Wavelet](https://github.com/pedrofrodenas/blur-Detection-Haar-Wavelet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45fd81e8-7279-4550-924c-502033f4a1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pywt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bbbd96c-ae28-4daf-9ff9-bed5fb9cfe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur_detect(img, threshold):\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    Y = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \n",
    "    M, N = Y.shape\n",
    "    \n",
    "    # Crop input image to be 3 divisible by 2\n",
    "    Y = Y[0:int(M/16)*16, 0:int(N/16)*16]\n",
    "    \n",
    "    # Step 1, compute Haar wavelet of input image\n",
    "    LL1,(LH1,HL1,HH1)= pywt.dwt2(Y, 'haar')\n",
    "    # Another application of 2D haar to LL1\n",
    "    LL2,(LH2,HL2,HH2)= pywt.dwt2(LL1, 'haar') \n",
    "    # Another application of 2D haar to LL2\n",
    "    LL3,(LH3,HL3,HH3)= pywt.dwt2(LL2, 'haar')\n",
    "    \n",
    "    # Construct the edge map in each scale Step 2\n",
    "    E1 = np.sqrt(np.power(LH1, 2)+np.power(HL1, 2)+np.power(HH1, 2))\n",
    "    E2 = np.sqrt(np.power(LH2, 2)+np.power(HL2, 2)+np.power(HH2, 2))\n",
    "    E3 = np.sqrt(np.power(LH3, 2)+np.power(HL3, 2)+np.power(HH3, 2))\n",
    "    \n",
    "    M1, N1 = E1.shape\n",
    "\n",
    "    # Sliding window size level 1\n",
    "    sizeM1 = 8\n",
    "    sizeN1 = 8\n",
    "    \n",
    "    # Sliding windows size level 2\n",
    "    sizeM2 = int(sizeM1/2)\n",
    "    sizeN2 = int(sizeN1/2)\n",
    "    \n",
    "    # Sliding windows size level 3\n",
    "    sizeM3 = int(sizeM2/2)\n",
    "    sizeN3 = int(sizeN2/2)\n",
    "    \n",
    "    # Number of edge maps, related to sliding windows size\n",
    "    N_iter = int((M1/sizeM1)*(N1/sizeN1))\n",
    "    \n",
    "    Emax1 = np.zeros((N_iter))\n",
    "    Emax2 = np.zeros((N_iter))\n",
    "    Emax3 = np.zeros((N_iter))\n",
    "    \n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    # Sliding windows index of level 1\n",
    "    x1 = 0\n",
    "    y1 = 0\n",
    "    # Sliding windows index of level 2\n",
    "    x2 = 0\n",
    "    y2 = 0\n",
    "    # Sliding windows index of level 3\n",
    "    x3 = 0\n",
    "    y3 = 0\n",
    "    \n",
    "    # Sliding windows limit on horizontal dimension\n",
    "    Y_limit = N1-sizeN1\n",
    "    \n",
    "    while count < N_iter:\n",
    "        # Get the maximum value of slicing windows over edge maps \n",
    "        # in each level\n",
    "        Emax1[count] = np.max(E1[x1:x1+sizeM1,y1:y1+sizeN1])\n",
    "        Emax2[count] = np.max(E2[x2:x2+sizeM2,y2:y2+sizeN2])\n",
    "        Emax3[count] = np.max(E3[x3:x3+sizeM3,y3:y3+sizeN3])\n",
    "        \n",
    "        # if sliding windows ends horizontal direction\n",
    "        # move along vertical direction and resets horizontal\n",
    "        # direction\n",
    "        if y1 == Y_limit:\n",
    "            x1 = x1 + sizeM1\n",
    "            y1 = 0\n",
    "            \n",
    "            x2 = x2 + sizeM2\n",
    "            y2 = 0\n",
    "            \n",
    "            x3 = x3 + sizeM3\n",
    "            y3 = 0\n",
    "            \n",
    "            count += 1\n",
    "        \n",
    "        # windows moves along horizontal dimension\n",
    "        else:\n",
    "                \n",
    "            y1 = y1 + sizeN1\n",
    "            y2 = y2 + sizeN2\n",
    "            y3 = y3 + sizeN3\n",
    "            count += 1\n",
    "    \n",
    "    # Step 3\n",
    "    EdgePoint1 = Emax1 > threshold;\n",
    "    EdgePoint2 = Emax2 > threshold;\n",
    "    EdgePoint3 = Emax3 > threshold;\n",
    "    \n",
    "    # Rule 1 Edge Pojnts\n",
    "    EdgePoint = EdgePoint1 + EdgePoint2 + EdgePoint3\n",
    "    \n",
    "    n_edges = EdgePoint.shape[0]\n",
    "    \n",
    "    # Rule 2 Dirak-Structure or Astep-Structure\n",
    "    DAstructure = (Emax1[EdgePoint] > Emax2[EdgePoint]) * (Emax2[EdgePoint] > Emax3[EdgePoint]);\n",
    "    \n",
    "    # Rule 3 Roof-Structure or Gstep-Structure\n",
    "    \n",
    "    RGstructure = np.zeros((n_edges))\n",
    "\n",
    "    for i in range(n_edges):\n",
    "    \n",
    "        if EdgePoint[i] == 1:\n",
    "        \n",
    "            if Emax1[i] < Emax2[i] and Emax2[i] < Emax3[i]:\n",
    "            \n",
    "                RGstructure[i] = 1\n",
    "                \n",
    "    # Rule 4 Roof-Structure\n",
    "    \n",
    "    RSstructure = np.zeros((n_edges))\n",
    "\n",
    "    for i in range(n_edges):\n",
    "    \n",
    "        if EdgePoint[i] == 1:\n",
    "        \n",
    "            if Emax2[i] > Emax1[i] and Emax2[i] > Emax3[i]:\n",
    "            \n",
    "                RSstructure[i] = 1\n",
    "\n",
    "    # Rule 5 Edge more likely to be in a blurred image \n",
    "\n",
    "    BlurC = np.zeros((n_edges));\n",
    "\n",
    "    for i in range(n_edges):\n",
    "    \n",
    "        if RGstructure[i] == 1 or RSstructure[i] == 1:\n",
    "        \n",
    "            if Emax1[i] < threshold:\n",
    "            \n",
    "                BlurC[i] = 1                        \n",
    "        \n",
    "    # Step 6\n",
    "    Per = np.sum(DAstructure)/np.sum(EdgePoint)\n",
    "    \n",
    "    # Step 7\n",
    "    if (np.sum(RGstructure) + np.sum(RSstructure)) == 0:\n",
    "        \n",
    "        BlurExtent = 100\n",
    "    else:\n",
    "        BlurExtent = np.sum(BlurC) / (np.sum(RGstructure) + np.sum(RSstructure))\n",
    "    \n",
    "    return Per, BlurExtent\n",
    "\n",
    "def find_images(input_dir):\n",
    "    extensions = [\".jpg\", \".png\", \".jpeg\"]\n",
    "\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if os.path.splitext(file)[1].lower() in extensions:\n",
    "                yield os.path.join(root, file)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f320854-e36a-4e82-939a-4218c5965a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' -- ORIGINAL VERSION --\\ninput_dir = \"videos/keyframes\"  # Change this to your image directory\\nsave_path = \"videos/result.json\"  # Change this to your desired output JSON file\\nthreshold = 35\\nminZero = 0.001\\n    \\nresults = []\\n\\nfor input_path in find_images(input_dir):\\n    try:\\n        I = cv2.imread(input_path)\\n        per, blurext = blur_detect(I, threshold)\\n        if per < minZero:\\n            classification = True\\n        else:\\n            classification = False\\n        results.append({\"input_path\": input_path, \"per\": per, \"blur extent\": blurext, \"is blur\": classification})\\n        print(\"{0}, Per: {1:.5f}, blur extent: {2:.3f}, is blur: {3}\".format(input_path, per, blurext, classification))\\n        \\n        \\n    except Exception as e:\\n        print(e)\\n        pass\\n    \\nif save_path:\\n    \\n    assert os.path.splitext(save_path)[1] == \".json\", \"You must include the extension .json on the end of the save path\"\\n    \\n    with open(save_path, \\'w\\') as outfile:\\n        json.dump(results, outfile, sort_keys=True, indent=4)\\n        outfile.write(\"\\n\")\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parser = argparse.ArgumentParser(description='run Haar Wavelet blur detection on a folder')\n",
    "# parser.add_argument('-i', '--input_dir', dest=\"input_dir\", type=str, required=True, help=\"directory of images\")\n",
    "# parser.add_argument('-s', '--save_path', dest='save_path', type=str, help=\"path to save output\")\n",
    "# parser.add_argument(\"-t\", \"--threshold\", dest='threshold', type=float, default=35, help=\"blurry threshold\")\n",
    "# parser.add_argument(\"-d\", \"--decision\", dest='MinZero', type=float, default=0.001, help=\"MinZero Decision Threshold\")\n",
    "# args = parser.parse_args()\n",
    "''' -- ORIGINAL VERSION --\n",
    "input_dir = \"videos/keyframes\"  # Change this to your image directory\n",
    "save_path = \"videos/result.json\"  # Change this to your desired output JSON file\n",
    "threshold = 35\n",
    "minZero = 0.001\n",
    "    \n",
    "results = []\n",
    "\n",
    "for input_path in find_images(input_dir):\n",
    "    try:\n",
    "        I = cv2.imread(input_path)\n",
    "        per, blurext = blur_detect(I, threshold)\n",
    "        if per < minZero:\n",
    "            classification = True\n",
    "        else:\n",
    "            classification = False\n",
    "        results.append({\"input_path\": input_path, \"per\": per, \"blur extent\": blurext, \"is blur\": classification})\n",
    "        print(\"{0}, Per: {1:.5f}, blur extent: {2:.3f}, is blur: {3}\".format(input_path, per, blurext, classification))\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "    \n",
    "if save_path:\n",
    "    \n",
    "    assert os.path.splitext(save_path)[1] == \".json\", \"You must include the extension .json on the end of the save path\"\n",
    "    \n",
    "    with open(save_path, 'w') as outfile:\n",
    "        json.dump(results, outfile, sort_keys=True, indent=4)\n",
    "        outfile.write(\"\\n\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f6117d5-2e7f-4aca-8f41-d6b8b5d24209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8303008466942893\n",
      "videos/keyframes/24.jpg\n"
     ]
    }
   ],
   "source": [
    "input_dir = \"videos/keyframes\"  # Change this to your image directory\n",
    "save_path = \"videos/result.json\"  # Change this to your desired output JSON file\n",
    "threshold = 35\n",
    "minZero = 0.001\n",
    "    \n",
    "results = []\n",
    "best_result = 1.0\n",
    "best_result_path = \"\"\n",
    "for input_path in find_images(input_dir):\n",
    "    try:\n",
    "        I = cv2.imread(input_path)\n",
    "        per, blurext = blur_detect(I, threshold)\n",
    "        # if per < minZero:\n",
    "        #     classification = True\n",
    "        # else:\n",
    "        #     classification = False\n",
    "        if blurext < best_result:\n",
    "            best_result = blurext\n",
    "            best_result_path = input_path\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "    \n",
    "\n",
    "\n",
    "print (best_result)\n",
    "print (best_result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b531c89-b0b4-43cc-8d86-5bbd56998b90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
